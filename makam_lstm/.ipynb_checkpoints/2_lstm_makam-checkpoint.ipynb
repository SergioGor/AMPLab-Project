{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "normalization = 'minmax'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First we list all the files\n",
    "scorelist=os.listdir('SymbTr-master/txt')\n",
    "#Filter out the ones that are not .txt\n",
    "scorelist = [k for k in scorelist if '.txt' in k]\n",
    "scorelist.sort()\n",
    "makamscore_dir = list()\n",
    "#Nest by makam\n",
    "for score in scorelist:\n",
    "    makam = {'makam':score.split('--')[0], 'scores':[k for k in scorelist if score.split('--')[0] == k.split('--')[0]]}\n",
    "    if makam not in makamscore_dir:\n",
    "        makamscore_dir.append(makam)\n",
    "#Sort makams by number of scores\n",
    "makamscore_dir.sort(key=lambda k:len(k['scores']), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We take the three best respresented makams\n",
    "makamscore_dir = makamscore_dir[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processScore(file):\n",
    "    #Given a .txt, provides a numpy array with [note, duration]\n",
    "    columns = ['Sira', 'Kod', 'Nota53', 'NotaAE', 'Koma53', 'KomaAE', \n",
    "         'Pay', 'Payda', 'Ms', 'LNS', 'Bas', 'Soz1', 'Offset']\n",
    "    df = pd.DataFrame(columns = columns)\n",
    "    with open('SymbTr-master/txt/'+file) as f: \n",
    "        for n, line in enumerate(f):\n",
    "            if n > 0:\n",
    "                auxdf = pd.DataFrame(data = line.strip().split(\"\\t\")).T\n",
    "                auxdf.columns = columns\n",
    "                df = df.append(auxdf)\n",
    "                \n",
    "    offsets=df[df['Kod'].isin(['9', '10'])]['Offset'].values.astype(np.float)\n",
    "    notes=df[df['Kod'].isin(['9', '10'])]['Koma53'].values.astype(np.float)\n",
    "    notes[notes == -1] = 242 #We substitute silence note value for min-1 in the whole dataset\n",
    "    offsets=np.hstack((offsets, offsets[-1]+1.0))\n",
    "    durations =  (offsets[1:]-offsets[0:-1])\n",
    "    notedur = np.vstack((notes, durations))\n",
    "    return notedur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will stack the whole dataset in order to obtain note statics for normalization\n",
    "whole_dataset = np.zeros((2,0))\n",
    "for makam in makamscore_dir:\n",
    "    scorelist = makam['scores']\n",
    "    for i,score in enumerate(scorelist):\n",
    "        x = processScore(score)\n",
    "        whole_dataset = np.hstack((whole_dataset, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notemin = np.min(whole_dataset, axis=1)\n",
    "notemean = np.mean(whole_dataset, axis=1)\n",
    "notemax = np.max(whole_dataset, axis=1)\n",
    "notestd = np.std(whole_dataset, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('makamscore_dir.npy', makamscore_dir)\n",
    "np.save('notemin.npy', notemin)\n",
    "np.save('notemean.npy', notemean)\n",
    "np.save('notestd.npy', notestd)\n",
    "np.save('notemax.npy', notemax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 starts. Average MSE:\n",
      "0.006928244511893923\n",
      "Epoch 2 starts. Average MSE:\n",
      "0.006102367428130353\n",
      "Epoch 3 starts. Average MSE:\n",
      "0.005750374587720355\n",
      "Epoch 4 starts. Average MSE:\n",
      "0.005727278195399143\n",
      "Epoch 5 starts. Average MSE:\n",
      "0.005713071831135281\n",
      "Epoch 6 starts. Average MSE:\n",
      "0.005702111993855211\n",
      "Epoch 7 starts. Average MSE:\n",
      "0.0056929902368233155\n",
      "Epoch 8 starts. Average MSE:\n",
      "0.005684863562891579\n",
      "Epoch 9 starts. Average MSE:\n",
      "0.005677533359715123\n",
      "Epoch 10 starts. Average MSE:\n",
      "0.005671108606464463\n",
      "Epoch 11 starts. Average MSE:\n",
      "0.0056656379085098536\n",
      "Epoch 12 starts. Average MSE:\n",
      "0.005659839918066617\n",
      "Epoch 13 starts. Average MSE:\n",
      "0.00565305516198291\n",
      "Epoch 14 starts. Average MSE:\n",
      "0.005646673877345821\n",
      "Epoch 15 starts. Average MSE:\n",
      "0.005641671425516165\n",
      "Epoch 16 starts. Average MSE:\n",
      "0.005638072491529734\n",
      "Epoch 17 starts. Average MSE:\n",
      "0.005635434394821619\n",
      "Epoch 18 starts. Average MSE:\n",
      "0.005633413258031596\n",
      "Epoch 19 starts. Average MSE:\n",
      "0.005631768142385289\n",
      "Epoch 20 starts. Average MSE:\n",
      "0.005630352910094053\n",
      "Epoch 21 starts. Average MSE:\n",
      "0.005629145336188854\n",
      "Epoch 22 starts. Average MSE:\n",
      "0.005628209246557472\n",
      "Epoch 23 starts. Average MSE:\n",
      "0.005627423722905463\n",
      "Epoch 24 starts. Average MSE:\n",
      "0.005626779818275818\n",
      "Epoch 25 starts. Average MSE:\n",
      "0.0056262424002377544\n",
      "Epoch 1 starts. Average MSE:\n",
      "0.008785946724005315\n",
      "Epoch 2 starts. Average MSE:\n",
      "0.008776459908897093\n",
      "Epoch 3 starts. Average MSE:\n",
      "0.00877051782026158\n",
      "Epoch 4 starts. Average MSE:\n",
      "0.008765844966529279\n",
      "Epoch 5 starts. Average MSE:\n",
      "0.008762515843455734\n",
      "Epoch 6 starts. Average MSE:\n",
      "0.00875992561645934\n",
      "Epoch 7 starts. Average MSE:\n",
      "0.008758096971280889\n",
      "Epoch 8 starts. Average MSE:\n",
      "0.008756510492587466\n",
      "Epoch 9 starts. Average MSE:\n",
      "0.008755334995973998\n",
      "Epoch 10 starts. Average MSE:\n",
      "0.008754218070423725\n",
      "Epoch 11 starts. Average MSE:\n",
      "0.008753307830440343\n",
      "Epoch 12 starts. Average MSE:\n",
      "0.008752501270060097\n",
      "Epoch 13 starts. Average MSE:\n",
      "0.008751890774956219\n",
      "Epoch 14 starts. Average MSE:\n",
      "0.00875135197479672\n",
      "Epoch 15 starts. Average MSE:\n",
      "0.008750961962636822\n",
      "Epoch 16 starts. Average MSE:\n",
      "0.008750686685022636\n",
      "Epoch 17 starts. Average MSE:\n",
      "0.00875048174165303\n",
      "Epoch 18 starts. Average MSE:\n",
      "0.008750411463314137\n",
      "Epoch 19 starts. Average MSE:\n",
      "0.008750371941074728\n",
      "Epoch 20 starts. Average MSE:\n",
      "0.008750316655921946\n",
      "Epoch 21 starts. Average MSE:\n",
      "0.008750346377958563\n",
      "Epoch 22 starts. Average MSE:\n",
      "0.008750326441166177\n",
      "Epoch 23 starts. Average MSE:\n",
      "0.008750373421128289\n",
      "Epoch 24 starts. Average MSE:\n",
      "0.008750343645895546\n",
      "Epoch 25 starts. Average MSE:\n",
      "0.008750316360349866\n",
      "Epoch 1 starts. Average MSE:\n",
      "0.005344418487044746\n",
      "Epoch 2 starts. Average MSE:\n",
      "0.005339488333965175\n",
      "Epoch 3 starts. Average MSE:\n",
      "0.005337755793309866\n",
      "Epoch 4 starts. Average MSE:\n",
      "0.005336702639336723\n",
      "Epoch 5 starts. Average MSE:\n",
      "0.005335901047441154\n",
      "Epoch 6 starts. Average MSE:\n",
      "0.005335228068322487\n",
      "Epoch 7 starts. Average MSE:\n",
      "0.005334667173758496\n",
      "Epoch 8 starts. Average MSE:\n",
      "0.00533418317849347\n",
      "Epoch 9 starts. Average MSE:\n",
      "0.00533376417164696\n",
      "Epoch 10 starts. Average MSE:\n",
      "0.005333402720185955\n",
      "Epoch 11 starts. Average MSE:\n",
      "0.005333088405687739\n",
      "Epoch 12 starts. Average MSE:\n",
      "0.005332816554908335\n",
      "Epoch 13 starts. Average MSE:\n",
      "0.00533257983577259\n",
      "Epoch 14 starts. Average MSE:\n",
      "0.005332373064687857\n",
      "Epoch 15 starts. Average MSE:\n",
      "0.005332192122425454\n",
      "Epoch 16 starts. Average MSE:\n",
      "0.005332033427701671\n",
      "Epoch 17 starts. Average MSE:\n",
      "0.005331894669051187\n",
      "Epoch 18 starts. Average MSE:\n",
      "0.005331773351817005\n",
      "Epoch 19 starts. Average MSE:\n",
      "0.0053316674223488495\n",
      "Epoch 20 starts. Average MSE:\n",
      "0.0053315739030883455\n",
      "Epoch 21 starts. Average MSE:\n",
      "0.005331490188472174\n",
      "Epoch 22 starts. Average MSE:\n",
      "0.005331414588338768\n",
      "Epoch 23 starts. Average MSE:\n",
      "0.00533134522240017\n",
      "Epoch 24 starts. Average MSE:\n",
      "0.005331281146087407\n",
      "Epoch 25 starts. Average MSE:\n",
      "0.005331222179176329\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "normalization = 'minmax'\n",
    "makamscore_dir = np.load('makamscore_dir.npy')\n",
    "notemin = np.load('notemin.npy')\n",
    "notestd = np.load('notestd.npy')\n",
    "notemean = np.load('notemean.npy')\n",
    "notemax = np.load('notemax.npy')\n",
    "\n",
    "def processScore(file):\n",
    "    #Given a .txt, provides a numpy array with [note, duration]\n",
    "    columns = ['Sira', 'Kod', 'Nota53', 'NotaAE', 'Koma53', 'KomaAE', \n",
    "         'Pay', 'Payda', 'Ms', 'LNS', 'Bas', 'Soz1', 'Offset']\n",
    "    df = pd.DataFrame(columns = columns)\n",
    "    with open('SymbTr-master/txt/'+file) as f: \n",
    "        for n, line in enumerate(f):\n",
    "            if n > 0:\n",
    "                auxdf = pd.DataFrame(data = line.strip().split(\"\\t\")).T\n",
    "                auxdf.columns = columns\n",
    "                df = df.append(auxdf)\n",
    "                \n",
    "    offsets=df[df['Kod'].isin(['9', '10'])]['Offset'].values.astype(np.float)\n",
    "    notes=df[df['Kod'].isin(['9', '10'])]['Koma53'].values.astype(np.float)\n",
    "    notes[notes == -1] = 242 #We substitute silence note value for min-1 in the whole dataset\n",
    "    offsets=np.hstack((offsets, offsets[-1]+1.0))\n",
    "    durations =  (offsets[1:]-offsets[0:-1])\n",
    "    notedur = np.vstack((notes, durations))\n",
    "    return notedur\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, hidden_dim, batch_size, output_dim=1,\n",
    "                    num_layers=2):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.batch_size = batch_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # Define the LSTM layer\n",
    "        self.lstm = nn.LSTM(self.input_dim, self.hidden_dim, self.num_layers)\n",
    "\n",
    "        # Define the output layer\n",
    "        self.linear = nn.Linear(self.hidden_dim, output_dim)\n",
    "\n",
    "    def init_hidden(self):\n",
    "        # This is what we'll initialise our hidden state as\n",
    "        return (torch.zeros(self.num_layers, self.batch_size, self.hidden_dim),\n",
    "                torch.zeros(self.num_layers, self.batch_size, self.hidden_dim))\n",
    "\n",
    "    def forward(self, input):\n",
    "        # Forward pass through LSTM layer\n",
    "        # shape of lstm_out: [input_size, batch_size, hidden_dim]\n",
    "        # shape of self.hidden: (a, b), where a and b both \n",
    "        # have shape (num_layers, batch_size, hidden_dim).\n",
    "        lstm_out, self.hidden = self.lstm(input.view(len(input), self.batch_size, -1))\n",
    "        \n",
    "        # Only take the output from the final timetep\n",
    "        y_pred = self.linear(lstm_out[-1].view(self.batch_size, -1))\n",
    "        return y_pred.view(-1)\n",
    "\n",
    "model = LSTM(input_dim=2, hidden_dim=1024, batch_size=1, output_dim=2, num_layers=1)\n",
    "\n",
    "def trainMAKAM(scorelist):\n",
    "    scoreind = np.zeros(len(scorelist)+1)\n",
    "    makam = np.zeros((2,0))\n",
    "    for i,score in enumerate(scorelist):\n",
    "        x = processScore(score)\n",
    "        makam = np.hstack((makam, x))\n",
    "        scoreind[i]=x.shape[1]\n",
    "\n",
    "    scoreind[-1]=makam.shape[1]\n",
    "    reset = np.zeros(len(scorelist)+1)\n",
    "    for i in range(len(scoreind)):\n",
    "        reset[i]=np.sum(scoreind[:i])\n",
    "\n",
    "    #Normalize the sequences\n",
    "    if normalization == 'minmax':\n",
    "        makam = (makam - np.swapaxes(np.tile(notemin, (makam.shape[1],1)), 0,1)) / (np.swapaxes(np.tile(notemax, (makam.shape[1],1)), 0,1) - np.swapaxes(np.tile(notemin, (makam.shape[1],1)), 0,1))\n",
    "    elif normalization == 'standarize':\n",
    "        makam = (makam - np.swapaxes(np.tile(notemean, (makam.shape[1],1)), 0,1)) / np.swapaxes(np.tile(notestd, (makam.shape[1],1)), 0,1)\n",
    "\n",
    "    makam = np.expand_dims(np.swapaxes(makam,0,1),1)\n",
    "\n",
    "    inputs = torch.from_numpy(makam[:-1,:,:])\n",
    "    targets = torch.from_numpy(makam[1:,:,:])\n",
    "\n",
    "    model.double()\n",
    "    if torch.cuda.is_available():\n",
    "        model.cuda()\n",
    "        inputs = inputs.cuda()\n",
    "        targets = targets.cuda()\n",
    "        criterion = nn.MSELoss().cuda()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "    else:\n",
    "        criterion = nn.MSELoss()\n",
    "\n",
    "    epochs = 25\n",
    "    running_loss = 0.0\n",
    "    best = 100.0\n",
    "\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print('Epoch '+str(epoch+1)+' starts. Average MSE:')\n",
    "        running_loss = 0.0\n",
    "        for k in range(len(inputs)):\n",
    "            if k in reset:\n",
    "                model.hidden = model.init_hidden()\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs[k])\n",
    "            loss = criterion(outputs, targets[k])\n",
    "            loss.backward()\n",
    "            running_loss += loss.item()\n",
    "            optimizer.step()\n",
    "        print(running_loss/len(inputs))\n",
    "        if running_loss/len(inputs) < best:\n",
    "            best = running_loss/len(inputs)\n",
    "            torch.save(model.state_dict(), scorelist[0].split('--')[0]+'.pt')\n",
    "    return model\n",
    "\n",
    "## Makam-wise 2-layer LSTM training\n",
    "\n",
    "hicaz = trainMAKAM(makamscore_dir[0]['scores'])\n",
    "nihavent = trainMAKAM(makamscore_dir[1]['scores'])\n",
    "ussak = trainMAKAM(makamscore_dir[2]['scores'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of similarity with Euclidean Distance of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_distance(model1, model2):\n",
    "\n",
    "    model.load_state_dict(torch.load(model1+'.pt'))\n",
    "    params1 = model.lstm.all_weights.copy()\n",
    "    cpu_param1 = list()\n",
    "    for param in params1[0]:\n",
    "        cpu_param1.append(param.cpu().detach().numpy())\n",
    "\n",
    "    model.load_state_dict(torch.load(model2+'.pt'))\n",
    "    params2 = model.lstm.all_weights.copy()\n",
    "    cpu_param2 = list()\n",
    "    for param in params2[0]:\n",
    "        cpu_param2.append(param.cpu().detach().numpy())\n",
    "    distance = 0.0\n",
    "    for p in range(len(cpu_param1)):\n",
    "        distance += np.sqrt(np.sum((cpu_param1[p]-cpu_param2[p])**2))\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51.03200432247304"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LSTM_distance('hicaz', 'nihavent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79.8481377025653"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LSTM_distance('hicaz', 'ussak')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38.686150534999015"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LSTM_distance('ussak', 'nihavent')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
